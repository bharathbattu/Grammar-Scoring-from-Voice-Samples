{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f7ef1f",
   "metadata": {},
   "source": [
    "\n",
    "# Grammar Scoring from Voice Samples — Colab (Pipeline A, Audio Mode 3)\n",
    "\n",
    "This Colab notebook runs the full pipeline end-to-end:\n",
    "\n",
    "- Clone your GitHub repo\n",
    "- Install dependencies (quietly)\n",
    "- Auto-detect audio in `data/sample_audio/` **or** let you upload your own\n",
    "- Transcribe with Whisper **small** (faster-whisper)\n",
    "- Extract grammar errors, fillers, WPM\n",
    "- Score & explain (0–100)\n",
    "- Visualize component penalties + overall score gauge\n",
    "- Optional batch evaluation if multiple files are provided\n",
    "\n",
    "> **Model:** `small` (balanced speed/accuracy)  \n",
    "> **Audio Mode 3:** auto-detect sample **or** upload on the fly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea18601",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Runtime & Config\n",
    "import os, sys, platform, subprocess, shutil, json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "print(\"GPU available (nvidia-smi):\", shutil.which(\"nvidia-smi\") is not None)\n",
    "if shutil.which(\"nvidia-smi\"):\n",
    "    _ = subprocess.run([\"nvidia-smi\", \"-L\"], check=False)\n",
    "\n",
    "# Configuration (edit if needed)\n",
    "REPO_URL = \"https://github.com/bharathbattu/Grammar-Scoring-from-Voice-Samples\"  #@param {type:\"string\"}\n",
    "BRANCH = \"main\"  #@param {type:\"string\"}\n",
    "MODEL_SIZE = \"small\"  #@param [\"tiny\", \"small\", \"medium\"]\n",
    "PROJECT_DIR = Path(\"/content/Grammar-Scoring-from-Voice-Samples\")\n",
    "APP_DIR = PROJECT_DIR / \"app\"\n",
    "DATA_DIR = PROJECT_DIR / \"data\" / \"sample_audio\"\n",
    "print(\"Repo:\", REPO_URL)\n",
    "print(\"Branch:\", BRANCH)\n",
    "print(\"Model size:\", MODEL_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44522cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Clone/refresh repository\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Clean any prior clone\n",
    "if Path(PROJECT_DIR).exists():\n",
    "    print(\"Removing existing project directory...\")\n",
    "    shutil.rmtree(PROJECT_DIR, ignore_errors=True)\n",
    "\n",
    "print(\"Cloning repo...\")\n",
    "_ = subprocess.run(\n",
    "    [\"git\", \"clone\", \"--depth\", \"1\", \"--branch\", BRANCH, REPO_URL, str(PROJECT_DIR)],\n",
    "    check=True\n",
    ")\n",
    "print(\"Done.\")\n",
    "print(\"Project files:\", list(PROJECT_DIR.iterdir())[:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Install Dependencies (quiet)\n",
    "import subprocess, shutil, sys, os\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\"] + pkgs\n",
    "    return subprocess.run(cmd, check=False)\n",
    "\n",
    "# Torch (choose CUDA if GPU present; otherwise CPU)\n",
    "if shutil.which(\"nvidia-smi\"):\n",
    "    print(\"Installing Torch with CUDA wheels... (this may take a minute)\")\n",
    "    pip_install([\"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
    "else:\n",
    "    print(\"Installing CPU Torch wheels...\")\n",
    "    pip_install([\"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cpu\"])\n",
    "\n",
    "# Install requirements from repo (fastapi, faster-whisper, pydantic v1, etc.)\n",
    "print(\"Installing requirements from repo...\")\n",
    "req_file = PROJECT_DIR / \"requirements.txt\"\n",
    "if req_file.exists():\n",
    "    pip_install([\"-r\", str(req_file)])\n",
    "else:\n",
    "    # minimal fallback (shouldn't happen since repo has requirements.txt)\n",
    "    pip_install([\"fastapi\", \"uvicorn[standard]\", \"pydantic<2\", \"faster-whisper\", \"language-tool-python\", \"jiwer\", \"numpy\", \"pandas\", \"matplotlib\"])\n",
    "\n",
    "# Ensure Java for language_tool_python (Colab often has it; install if missing)\n",
    "if not shutil.which(\"java\"):\n",
    "    print(\"Installing Java (for LanguageTool)...\")\n",
    "    subprocess.run([\"apt-get\", \"update\", \"-qq\"], check=False)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"openjdk-11-jre-headless\"], check=False)\n",
    "else:\n",
    "    print(\"Java found.\")\n",
    "\n",
    "print(\" Dependencies installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fec41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Import modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to sys.path\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "\n",
    "# Imports from the repo\n",
    "from app.asr import transcribe\n",
    "from app.text_features import grammar_errors, filler_count, words_per_minute, normalize_transcript\n",
    "from app.scoring import (\n",
    "    normalize_grammar_errors, normalize_fillers, normalize_wer,\n",
    "    fluency_penalty, calculate_final_score, generate_score_explanation\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\" Repo modules imported.\")\n",
    "print(\"Project root:\", PROJECT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Audio selection (Auto-detect or Upload)\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Sample audio dir:\", DATA_DIR)\n",
    "\n",
    "# Auto-detect first .wav or .mp3\n",
    "audio_files: List[Path] = list(DATA_DIR.glob(\"*.wav\")) + list(DATA_DIR.glob(\"*.mp3\"))\n",
    "audio_file: Optional[Path] = None\n",
    "\n",
    "if audio_files:\n",
    "    audio_file = audio_files[0]\n",
    "    print(f\"✓ Detected audio file in repo: {audio_file.name}\")\n",
    "else:\n",
    "    print(\"⚠ No audio found in repo. You can upload one now...\")\n",
    "\n",
    "# Offer upload if none detected (or if you want to override)\n",
    "try:\n",
    "    from google.colab import files  # type: ignore\n",
    "    do_upload = False if audio_file else True  # upload only if none found by default\n",
    "    if do_upload:\n",
    "        print(\"Opening browser file picker...\")\n",
    "        uploaded = files.upload()\n",
    "        for name, _ in uploaded.items():\n",
    "            src = Path(name)\n",
    "            target = DATA_DIR / src.name\n",
    "            src.replace(target)\n",
    "            audio_file = target\n",
    "            print(\"Saved to:\", target)\n",
    "    else:\n",
    "        print(\"Using auto-detected file. To upload instead, set do_upload=True in this cell and re-run.\")\n",
    "except Exception as e:\n",
    "    print(\"Upload widget not available (non-Colab env). Using detected file if any.\")\n",
    "\n",
    "if audio_file and audio_file.exists():\n",
    "    size_kb = audio_file.stat().st_size / 1024\n",
    "    print(f\"Selected: {audio_file.name}  ({size_kb:.2f} KB)\")\n",
    "else:\n",
    "    print(\"No audio file available. The notebook will fall back to an example transcript.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Optional: Waveform (if librosa available)\n",
    "try:\n",
    "    import librosa, librosa.display  # type: ignore\n",
    "    import numpy as np\n",
    "    if audio_file and audio_file.exists():\n",
    "        y, sr = librosa.load(str(audio_file), sr=None)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        librosa.display.waveshow(y, sr=sr, alpha=0.7)\n",
    "        plt.title(f\"Waveform: {audio_file.name}\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"Duration: {duration:.2f}s  |  Sample rate: {sr} Hz\")\n",
    "    else:\n",
    "        print(\"No audio file to visualize.\")\n",
    "except Exception as e:\n",
    "    print(\"Skipping waveform:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156edb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Transcribe with Whisper (small)\n",
    "from typing import Dict, Any\n",
    "\n",
    "if audio_file and audio_file.exists():\n",
    "    print(\"Transcribing... (first run may download model ~150MB)\")\n",
    "    asr_result: Dict[str, Any] = transcribe(str(audio_file), model_size=MODEL_SIZE)\n",
    "else:\n",
    "    print(\"No audio found. Using example transcript.\")\n",
    "    asr_result = {\n",
    "        \"transcript\": (\n",
    "            \"Um, hello. My name is John and, you know, I am applying \"\n",
    "            \"for this position. I has experience in data science.\"\n",
    "        ),\n",
    "        \"word_count\": 21,\n",
    "        \"duration_sec\": 8.5,\n",
    "        \"language\": \"en\"\n",
    "    }\n",
    "\n",
    "print(\"\\n=== ASR RESULT ===\")\n",
    "print(\"Transcript:\", asr_result[\"transcript\"][:300] + (\"...\" if len(asr_result[\"transcript\"])>300 else \"\"))\n",
    "print(\"Word count:\", asr_result[\"word_count\"])\n",
    "print(\"Duration (s):\", asr_result[\"duration_sec\"])\n",
    "print(\"Language:\", asr_result.get(\"language\", \"en\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Feature Extraction\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "transcript: str = asr_result[\"transcript\"]\n",
    "normalized_text: str = normalize_transcript(transcript)\n",
    "word_count: int = asr_result[\"word_count\"]\n",
    "duration_sec: float = asr_result[\"duration_sec\"]\n",
    "\n",
    "g_count: int\n",
    "g_details: List[Dict[str, Any]]\n",
    "g_count, g_details = grammar_errors(normalized_text, language=\"en-US\")\n",
    "\n",
    "f_count: int\n",
    "f_list: List[str]\n",
    "f_count, f_list = filler_count(normalized_text)\n",
    "\n",
    "wpm = words_per_minute(word_count, duration_sec)\n",
    "\n",
    "print(\"=== FEATURES ===\")\n",
    "print(\"Grammar errors:\", g_count)\n",
    "print(\"Fillers:\", f_count, \"|\", f_list[:10])\n",
    "print(\"WPM:\", wpm)\n",
    "\n",
    "# Show a compact table of grammar issues (top 10)\n",
    "if g_count > 0:\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            \"Rule ID\": e[\"rule_id\"],\n",
    "            \"Message\": e[\"message\"],\n",
    "            \"Context\": (e[\"context\"][:60] + \"...\") if len(e[\"context\"]) > 60 else e[\"context\"],\n",
    "            \"Suggestions\": \", \".join(e.get(\"replacements\", [])[:2]) if e.get(\"replacements\") else \"\"\n",
    "        }\n",
    "        for e in g_details[:10]\n",
    "    ])\n",
    "    from IPython.display import display\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"No grammar errors detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Scoring\n",
    "g_pen = normalize_grammar_errors(g_count, word_count)\n",
    "f_pen = normalize_fillers(f_count, word_count)\n",
    "wer_pen = normalize_wer(None)  # no reference in this notebook\n",
    "fl_pen = fluency_penalty(wpm)\n",
    "\n",
    "final_score = calculate_final_score(\n",
    "    grammar_penalty=g_pen,\n",
    "    filler_penalty=f_pen,\n",
    "    wer_penalty=wer_pen,\n",
    "    fluency_pen=fl_pen\n",
    ")\n",
    "\n",
    "explanation = generate_score_explanation(\n",
    "    grammar_penalty=g_pen,\n",
    "    filler_penalty=f_pen,\n",
    "    wer_penalty=wer_pen,\n",
    "    fluency_pen=fl_pen,\n",
    "    final=final_score\n",
    ")\n",
    "\n",
    "print(\"=== PENALTIES (0=best,1=worst) ===\")\n",
    "print(\"Grammar:\", round(g_pen, 3))\n",
    "print(\"Fillers:\", round(f_pen, 3))\n",
    "print(\"WER:    \", round(wer_pen, 3))\n",
    "print(\"Fluency:\", round(fl_pen, 3))\n",
    "\n",
    "print(\"\\n=== FINAL SCORE ===\")\n",
    "print(final_score, \"/ 100\")\n",
    "print(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Visualization\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "categories = [\"Grammar\\n(35%)\", \"Fillers\\n(25%)\", \"WER\\n(20%)\", \"Fluency\\n(20%)\"]\n",
    "penalties = [g_pen, f_pen, wer_pen, fl_pen]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot of penalties\n",
    "colors = ['#e74c3c' if p > 0.5 else '#f39c12' if p > 0.25 else '#27ae60' for p in penalties]\n",
    "ax1.barh(categories, penalties, color=colors, alpha=0.7)\n",
    "ax1.set_xlabel('Penalty [0=Perfect, 1=Worst]')\n",
    "ax1.set_title('Component Penalties')\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, p in enumerate(penalties):\n",
    "    ax1.text(p + 0.02, i, f'{p:.3f}', va='center')\n",
    "\n",
    "# Gauge-like overall score\n",
    "ax2.axis('off')\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "score_normalized = final_score / 100.0\n",
    "if score_normalized >= 0.8:\n",
    "    color = '#27ae60'; grade = 'Excellent'\n",
    "elif score_normalized >= 0.6:\n",
    "    color = '#f39c12'; grade = 'Good'\n",
    "elif score_normalized >= 0.4:\n",
    "    color = '#e67e22'; grade = 'Fair'\n",
    "else:\n",
    "    color = '#e74c3c'; grade = 'Needs Improvement'\n",
    "\n",
    "circle = Circle((0.5, 0.5), 0.35, color=color, alpha=0.3)\n",
    "ax2.add_patch(circle)\n",
    "ax2.text(0.5, 0.6, f'{final_score:.1f}', ha='center', va='center', fontsize=48, fontweight='bold', color=color)\n",
    "ax2.text(0.5, 0.4, 'out of 100', ha='center', va='center', fontsize=12, color='gray')\n",
    "ax2.text(0.5, 0.25, grade, ha='center', va='center', fontsize=16, fontweight='bold', color=color)\n",
    "ax2.set_title('Overall Proficiency Score', fontsize=14, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2118e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Batch Evaluation (if multiple files exist)\n",
    "from typing import Dict, Any, List\n",
    "import pandas as pd\n",
    "\n",
    "if DATA_DIR.exists():\n",
    "    files = list(DATA_DIR.glob(\"*.wav\")) + list(DATA_DIR.glob(\"*.mp3\"))\n",
    "    if len(files) > 1:\n",
    "        print(f\"Found {len(files)} files. Running batch...\")\n",
    "        results: List[Dict[str, Any]] = []\n",
    "        for i, ap in enumerate(files, 1):\n",
    "            try:\n",
    "                asr = transcribe(str(ap), model_size=MODEL_SIZE)\n",
    "                tnorm = normalize_transcript(asr[\"transcript\"])\n",
    "                g_c, _ = grammar_errors(tnorm, language=\"en-US\")\n",
    "                f_c, _ = filler_count(tnorm)\n",
    "                wpm_val = words_per_minute(asr[\"word_count\"], asr[\"duration_sec\"])\n",
    "                g_p = normalize_grammar_errors(g_c, asr[\"word_count\"])\n",
    "                f_p = normalize_fillers(f_c, asr[\"word_count\"])\n",
    "                fl_p = fluency_penalty(wpm_val)\n",
    "                score = calculate_final_score(g_p, f_p, 0.0, fl_p)\n",
    "                results.append({\n",
    "                    \"File\": ap.name,\n",
    "                    \"Words\": asr[\"word_count\"],\n",
    "                    \"Duration (s)\": asr[\"duration_sec\"],\n",
    "                    \"Grammar Errors\": g_c,\n",
    "                    \"Fillers\": f_c,\n",
    "                    \"WPM\": wpm_val,\n",
    "                    \"Score\": score\n",
    "                })\n",
    "                print(f\"[{i}/{len(files)}] {ap.name}: {score:.2f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{i}/{len(files)}] {ap.name}: ERROR -> {e}\")\n",
    "        if results:\n",
    "            df = pd.DataFrame(results).sort_values(\"Score\", ascending=False)\n",
    "            print(\"\\n=== BATCH RESULTS ===\")\n",
    "            from IPython.display import display\n",
    "            display(df)\n",
    "            print(\"Average score:\", round(df[\"Score\"].mean(), 2))\n",
    "    else:\n",
    "        print(\"Only one audio file found. Add more files to enable batch evaluation.\")\n",
    "else:\n",
    "    print(\"Sample audio directory not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66810196",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Model & Library Versions\n",
    "import importlib\n",
    "\n",
    "def safe_ver(mod_name):\n",
    "    try:\n",
    "        m = importlib.import_module(mod_name)\n",
    "        return getattr(m, \"__version__\", \"unknown\")\n",
    "    except Exception:\n",
    "        return \"not installed\"\n",
    "\n",
    "print(\"faster-whisper:\", safe_ver(\"faster_whisper\"))\n",
    "print(\"language_tool_python:\", safe_ver(\"language_tool_python\"))\n",
    "print(\"jiwer:\", safe_ver(\"jiwer\"))\n",
    "print(\"pandas:\", safe_ver(\"pandas\"))\n",
    "print(\"matplotlib:\", safe_ver(\"matplotlib\"))\n",
    "print(\"torch:\", safe_ver(\"torch\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
